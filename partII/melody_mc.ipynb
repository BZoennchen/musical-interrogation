{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melody Generation with Markov Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import music21 as m21\n",
    "import torch\n",
    "from preprocess import load_songs_in_kern, NoteEncoder, TERM_SYMBOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = NoteEncoder()\n",
    "scores = load_songs_in_kern('./../deutschl/erk')\n",
    "enc_songs = encoder.encode_songs(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0].show('mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(enc_songs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'longest melody: {max(len(m) for m in enc_songs)}')\n",
    "print(f'shortest melody: {min(len(m) for m in enc_songs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols = sorted(list(set([item for sublist in \n",
    "                           enc_songs for item in sublist])))\n",
    "stoi = {s:i+1 for i, s in enumerate(symbols)}\n",
    "stoi[TERM_SYMBOL] = 0\n",
    "itos = {i: s for s, i in stoi.items()}\n",
    "print(f'n_symbols: {len(itos)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((len(stoi), len(stoi)))\n",
    "for enc_song in enc_songs:\n",
    "    chs = [TERM_SYMBOL] + enc_song + [TERM_SYMBOL]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f'There are {len(N[N > 0.0])/len(stoi)**2 *100} % non-zero entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = N.float()\n",
    "P = P / P.sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 6})\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(P, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_scores = 5\n",
    "generated_encoded_songs = []\n",
    "for _ in range(n_scores):\n",
    "    generated_encoded_song = []\n",
    "    char = '.'\n",
    "    while True:\n",
    "        ix = torch.multinomial(P[stoi[char]], num_samples=1, replacement=True).item()\n",
    "        char = itos[ix]\n",
    "        if char == '.':\n",
    "            break\n",
    "        generated_encoded_song.append(char)\n",
    "        #break\n",
    "    len(generated_encoded_song)\n",
    "    generated_encoded_songs.append(generated_encoded_song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_songs = list(map(lambda generated_encoded_song: encoder.decode_song(generated_encoded_song), generated_encoded_songs))\n",
    "generated_songs[4].show('mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelyhood = 0.0\n",
    "n = 0\n",
    "for m in enc_songs:\n",
    "    chs = ['.'] + m + ['.']\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        prob = P[ix1, ix2]\n",
    "        logprob = torch.log(prob)\n",
    "        log_likelyhood += logprob\n",
    "        n += 1\n",
    "        #print(f'{ch1}->{ch2}: {prob:.4f}')\n",
    "\n",
    "print(f'{log_likelyhood=}')\n",
    "nll = -log_likelyhood\n",
    "print(f'avg negative log likelyhood: {(nll/n)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
