{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\\\"https://colab.research.google.com/github/bearpelican/musicautobot/blob/master/notebooks/music_transformer/Generate_colab.ipynb\\\" target=\\\"_parent\\\"><img src=\\\"https://colab.research.google.com/assets/colab-badge.svg\\\" alt=\\\"Open In Colab\\\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Net\n",
    "\n",
    "Im folgenden wollen wir eines der einfachsten neuronalen Netze für die Melodiegenerierung verwenden: Ein Netwerk mit lediglich einer Schicht, d.h., die Parameter $\\theta$ stecken alle in einer einzigen Matrix $W$.\n",
    "\n",
    "Gegeben eines Vektors $\\mathbf{x}$ der eine Note/Event repräsentiert soll \n",
    "\n",
    "$$\\mathbf{x}^{\\top} W$$\n",
    "\n",
    "die nächste Note/Event ergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import music21 as m21\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from preprocess import load_songs_in_kern, NoteEncoder, StringToIntEncoder, TERM_SYMBOL\n",
    "\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da wir diesesmal unser Netzwerk trainieren, verwenden wir die GPU, sofern dies möglich ist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "print(f'{device=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Datenvorbereitung (wie zuvor)\n",
    "\n",
    "Zunächst laden wir unsere (1700 **einstimmigen**) Musikstücke aus denen wir die Frequenzen berechnen wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = load_songs_in_kern('./../deutschl/erk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns eines der Musikstücke anhören oder auch anzeigen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0].show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstes verwandeln wir die Noten in gut leserliche Zeichenketten, wobei jede Note durch genau eine Zeichenkette repräsentiert wird und zwar der Form ``MIDI-Note/Länge in vielfaches von time_step``.\n",
    "\n",
    "Dies übernimmt der ``NoteEncoder``. Dieser transponiert die Musikstücke zusätzlich nach C-Dur.\n",
    "Dieser filtert zugleich Musikstücke heraus, welche wir mit unserem ``time_step`` nicht abbilden können.\n",
    "Z.B. wenn ``time_step = 1/8`` dann können wir keine ``1/16``-Noten oder auch ``1/8 + 1/16``-Noten abbilden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_step = 1/8\n",
    "print(f'one timestep represents {time_step} beats')\n",
    "\n",
    "encoder = NoteEncoder(time_step)\n",
    "enc_songs, invalid_song_indices = encoder.encode_songs(scores)\n",
    "\n",
    "print(f'there are {len(enc_songs)} valid songs and {len(invalid_song_indices)} songs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(enc_songs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'longest melody: {max(len(m) for m in enc_songs)}')\n",
    "print(f'shortest melody: {min(len(m) for m in enc_songs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da der Computer besser mit Zahlen umgehen kann bauen wir uns eine Abbildung von den jeweiligen Zeichenketten zu Zahlen $$\\{0, 1, 2, \\ldots, m-1\\}$$ und umgekehrt. Dies übernimmt ``StringToIntEncoder``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_to_int = StringToIntEncoder(enc_songs)\n",
    "print(f'number of unique symbols: {len(string_to_int)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores[0].show('midi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Konstruktion der Trainingsdaten\n",
    "\n",
    "Statt die Übergänge direkt zu zählen, ist jeder Notenübergang von $e_i$ nach $e_j$.\n",
    "\n",
    "$\\mathbf{x}$ wird durch einen Vektor repräsentiert der $m$ Komponenten besitzt wobei $m$ die Anzahl an verschiedenen Noten ist. $\\mathbf{x}$ hat genau einen Eintrag der 1 ist alle anderen sind 0. Diese Art der Codierung nennt sich *one-hot Encoding*.\n",
    "\n",
    "$X$ ist eine Matrix die alle $\\mathbf{x}$ als Zeilenvektoren enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = len(string_to_int)\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "for enc_song in enc_songs:\n",
    "    chs = [TERM_SYMBOL] + enc_song + [TERM_SYMBOL]\n",
    "    for ch1, ch2 in zip(chs, chs[1:]):\n",
    "        ix1 = string_to_int.encode(ch1)\n",
    "        ix2 = string_to_int.encode(ch2)\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "\n",
    "xs = torch.tensor(xs, device=device)\n",
    "y = torch.tensor(ys, device=device)\n",
    "\n",
    "# one-hot-encoding\n",
    "# macht aus z.B. aus [0,2,1,3,2] den tensor\n",
    "# [[0,0,0,1],[0,1,0,0],[0,0,1,0],[1,0,0,0],[0,1,0,0]]\n",
    "X = F.one_hot(xs, num_classes=m).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.randn((m, m), requires_grad=True, device=device)\n",
    "print(f'matrix W has the shape {W.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Forwardpass berechnet sich wie folgt: Zuerst multiplizieren wir die beiden Matrizen \n",
    "\n",
    "$$C = X \\cdot W.$$\n",
    "\n",
    "Dann berechnen **zeilenweise** die sog. *softmax* operation.\n",
    "\n",
    "$$\\frac{\\exp(c_k)}{\\sum_{j=1} \\exp(c_j) }$$\n",
    "\n",
    "oder anders ausgedrückt **normieren** wir jede Zeile nachdem wir komponentenweise die exponentialfunktion angewendet haben. Eine Zeile der resultierenden Matrix $P$ kann somit als Wahrscheinlichkeitsverteilung interpretiert werden!\n",
    "\n",
    "Für die Optimierung durch *Gradient Decent* benötigen wir eine geeignete *Kostenfunktion*/*Lossfunction* $L$.\n",
    "Dazu betrachten wir jene \"Wahrscheinlichkeit\" für alle richtig gewählten Übergänge, d.h. die *Likelihood*.\n",
    "Seien $p_1, \\ldots, p_n$ diese Wahrscheinlichkeiten (eine pro Übergäng aka Zeile in $X$) dann ist \n",
    "\n",
    "$$p_1 \\cdot \\ldots \\cdot p_n$$\n",
    "\n",
    "die *Likelihood*.\n",
    "Um stattdessen addieren zu können berechnen wir jedoch die *negative log Likelihood*:\n",
    "\n",
    "$$-(\\log(p_1) + \\ldots + \\log(p_n).$$\n",
    "\n",
    "Durch den Aufruf ``loss.backward()`` wird die *Backpropagation* (auch *Backwardpass*) durchgeführt und wir können unsere Gewichte durch\n",
    "\n",
    "$$W \\leftarrow W - \\eta \\cdot \\nabla_W L $$\n",
    "\n",
    "In unserem Fall wählen wir eine sehr große *Lernrate* $\\eta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training aka gradient decent\n",
    "epochs = 500\n",
    "for k in range(epochs):\n",
    "    # 1. forward pass\n",
    "    logits = X @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(dim=1, keepdim=True)\n",
    "    loss = -probs[torch.arange(len(ys), device=device), y].log().mean()\n",
    "    \n",
    "    if k % 100 == 0:\n",
    "        print(f'epoch {k}, loss: {loss.item()}')\n",
    "    \n",
    "    # 2. backward pass\n",
    "    W.grad = None # set gradients to zero\n",
    "    loss.backward()\n",
    "    W.data += -10.0 * W.grad  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Melodiegenerierung  (wie zuvor)\n",
    "\n",
    "Wie zuvor allerdings müssen wir $P$ aus $W$ berechnen. **Achtung:** $P$ ist nicht gleich der *Markov-Matrix* von zuvor allerdings konvergiert es gegen diese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = W.exp() / W.exp().sum(dim=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit $P$ können wir nun neue Melodien generieren.\n",
    "Wir starten mit dem speziellen Symbol $e_1$ = ``TERM_SYMBOL`` (\"Beginn des Stücks\") als unsere erste Note/Event $e_1$. Dann berechnen wir $e_2$ aus der bedingten Verteilung $P(X_2 = e_2 | X_1 = e_1)$, gegeben durch die Zeile die zu $e_1$ gehört, ziehen. Als nächstes berechnen wir $e_3$ durch $P(X_2 = e_3 | X_1 = e_2)$.\n",
    "\n",
    "Diesen Vorgang führen wir so lange fort bis wir irgendwann ``TERM_SYMBOL`` ziehen.\n",
    "Sie können eine maximale Länge des Stücks festlegen und auch einen Anfang eines Stücks mitliefern.\n",
    "\n",
    "``temperature`` bestimmt wie stark die vom Modell gelernte Wahrscheinlichkeitsverteilung beachtet wird.\n",
    "\n",
    "+ ``temperature`` gleich 1.0 bedeutet, dass von der Wahrscheinlichkeitsverteilung gesampelt wird.\n",
    "+ ``temperature`` gegen unendlich bedeutet, dass gleichverteilt gesampelt wird (mehr Variation)\n",
    "+ ``temperature`` gegen 0 bedeutet, dass die hohe Wahrscheinlichkeiten verstärkt werden (weniger Variation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_event_number(char:str, temperature:float):\n",
    "    with torch.no_grad():\n",
    "        distribution = P[string_to_int.encode(char)] / temperature\n",
    "        ix = torch.multinomial(distribution, num_samples=1, replacement=True).item()\n",
    "        return ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(seq: list[str]=None, max_len:int=None, temperature:float=1.0):\n",
    "    generated_encoded_song = []\n",
    "    if seq != None:\n",
    "        generated_encoded_song = seq.copy()\n",
    "    char = TERM_SYMBOL\n",
    "    while max_len == None or max_len > len(generated_encoded_song):\n",
    "        ix = next_event_number(char, temperature)\n",
    "        char = string_to_int.decode(ix)\n",
    "        if char == TERM_SYMBOL:\n",
    "            break\n",
    "        generated_encoded_song.append(char)\n",
    "    return generated_encoded_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of songs we want to generate\n",
    "n_scores = 5\n",
    "generated_encoded_songs = []\n",
    "\n",
    "for _ in range(n_scores):\n",
    "    encoded_song = generate()\n",
    "    print(f'generated {\" \".join(encoded_song)} conisting of {len(encoded_song)} notes')\n",
    "    generated_encoded_songs.append(encoded_song)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Datennachbearbeitung (wie zuvor)\n",
    "\n",
    "Wir wollen uns die generierten Stücke natürlich anhören. Der ``NoteEncoder`` kann dies für uns übernehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_scores = encoder.decode_songs(generated_encoded_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_scores[0].show('midi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_scores[0].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
